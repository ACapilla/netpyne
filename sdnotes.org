* 14jun18 Created repo
* 14sep19 First improvements by Giljael and me
** README by Gil
1.How to add new cell types in the model: <plx_cellpopdata.py> Insert cell info in lists like PMd case.  popnames = ['PMd',
'ER2', 'IF2', 'IL2', 'ER5', 'EB5', 'IF5', 'IL5', 'ER6', 'IF6', 'IL6'] popclasses = [-1, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3] #
Izhikevich population type popEorI = [ 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1] # Whether it's excitatory or inhibitory popratios =
[numPMd,150, 25, 25, 167, 72, 40, 40, 192, 32, 32] Prior cells will have lower gids. E.g., PMd.gid < ER2.gid <...<IL6.gid

Change cellproperties() according to the cell types: cell info is returned to plx_model and the info is used for simulations.
For PMd type cells, the following is added, because the number of PMd cells are not changed as scale changes.  If cells
increase in the cell types as scale increases, the following modification is not needed.  indexPopName =
checkIndexPopName('PMd', popnames) # checkIndexPopName returns PMd index in popnames if not indexPopName == -1:
popnumbers[indexPopName] = numPMd # Number of PMds is fixed. # return back the number of PMd cells to numPMd.  "ncells" is a
global value, and total number of cells in the model.

According to the cell types added, return statement in names2inds() and its call in plx_cellpopdata.py and plx_model.py
should be updated.

def setconnprobs() needs connection probabilities for new cell types. Currently inserting PMds doesn't modify this function.

def setconnweights() needs new connection weight. For the PMds, connweights[PMd,ER2,AMPA]=10 was added.

<In plx_model.py> Update "## set cell types." @Line 189 For PMd, "elif cellclasses[c]==-1: celltypes.append(pmdnsloc)" is
added. pmdnsloc is defined in nsloc.py

Update "## set positions." @Line 202 Positions are changed. That is, if new cell types are added in the model, existing cells
in the model will have different positions because of randomness change.  xlocs = modelsize*rand(ncells) # Create random x
locations ylocs = modelsize*rand(ncells) # Create random y locations zlocs = verticalextent*rand(ncells) # Create random z
locations Add zlayer position update. For PMd, "elif cellnames[c][-1]=='d': zlocs[c]+=zlayerpositions[5]" is added. 'd' is in
'PMd'.

Update "## Actually create the cells." @Line 221 In this version(r2206 in SVN), all cells including new cells inserted are
distributed evenly in a round-robin way by "for c in xrange(int(pc.id()), ncells, nhosts):."  "cellsperhost" indicates how
many cells including new cell types inserted each worker created. Each worker might have different value of cellsperhost.
For PMd, the following code snippet is executed for NULL->NetCon->PMd connection. NSLOC-based cell types will follow the code
snippet, but inncl is only to feed PMds with external PMd spikes: if cellnames[gid] == 'PMd': cell = celltypes[gid](cellid =
gid) # create an NSLOC inncl.append(h.NetCon(None, cell)) # This netcon will receive external PMd spikes innclDic[gid] =
ninnclDic # This dictionary will be used for NetCon search.  ninnclDic += 1 else:

Update ##calculate distance and probabilities. @Line 256 Connection probabilities among cells are calculated prior to making
connections, However, PMds won't be post synaptic cells in the connections. So the following code snippet is only for PMds:
if cellnames[gid] == 'PMd': # There is no connection for cells -> PMds continue In order to make connections between the new
cells added and others based on probabilities, def setconnprobs() in plx_cellpopdata.py should be modified accordingly.
Connection between a ER2 and PMd is controlled explicitly by PMd[gid%numPMd]->ER2[gid]. So, if you want to control the
connections for other cells, follow the code for PMds:

pmdStart = cpd.popGidStart[PMd] # get pmd's start gid by using cpd.popGidStart[cellname] pmdEnd = cpd.popGidEnd[PMd] # get
PMd's end gid for c in xrange(pmdStart, pmdEnd + 1): allrands[c] = 1 # set all PMd values in allrands to 1.  if
cellnames[gid] == 'ER2': pMdId = (gid % numPMd) # select PMd being connected to this ER2 cell.  allconnprobs[pMdId] = 1 # to
make this PMd connected to the ER2 cell allrands[pMdId] = 0 # to make this PMd connected to the ER2 cell distances[pMdId] =
300 # to make the NetCon delay for this connection 5ms

Update ## Add background inputs @Line 447 ER2 and PMd cells won't be fired by background spikes. The following avoid them not
to be fired by background spikes: gid = gidvec[c] if isOriginal == 0: if cellnames[gid] == 'ER2' or cellnames[gid] ==
'PMd': # 'ER2' won't be fired by background stimulations.  continue

2.How to connect m1ms with Plexon?  # Connect m1ms with Plexon
- Copy m1ms/sim/Client to Windows machine having MATLAB and Plexon software.
- Open Client/plx_mat_interface.m on the Windows machine, and set up "remoteAddr" to the IP address m1ms runs on. In
  addition, set up "addapth" with the path for the library required for the Plexon software.
- Set up parameters in m1ms/sim/config.py accordingly.  isOriginal|isCommunication|isQueueTest a. 1 | x | x - To run the
  original m1ms (Cliff's parallelized model). X means don't care b. 0 | 1 | 1 - To run m1ms w/o connection to Plexon, but
  with PMd spike files c. 0 | 1 | 0 - To run m1ms, getting spikes from Plexon through the communication program Note: for b
  and c, check if PMd spike file (spikePMd-6sec.txv) is in data/.

3. How to run m1ms?  For 2.a, 2.b: $plx_runsim <# of workers>

For 2.c, 1. $plx_runsim <# of workers> 2. Run client in the Windows machine.  3. Run the Plexon softsever.

4. How to plot raster, lfp and power spectra?  Spikes are stored in m1ms/sim/m1ms-spk.txt and m1ms-spk.txt.mat Just run
python fileplots.py m1ms-spk.txt. It stores plots to files.  $python fileplots.py m1ms-spk.txt



** List of changes by Gil
- Added PMd population receiving external input
- Cells (inlcuidng PMd) distributed over workers using round-robin (each worker doesnt have same number of cells)
- Cells not referenced by realtive id, so easier to add and reference cells
- Master worker gets data from PMd cells and broadcasts it to other workers
- With PMd data, 30 workers over 10 nodes, and 10 scale (7846 cells), this model (6sec sim) runs in real-time (6sec).
- Added P population (proprioceptive from virtual arm) and udp interface to arm
** List of changes by me
- Tidied up code and merged with cliff's tutorial code
- Included generic stimulation code based on classes, eg. class for 'natural touch', class for 'optogenetic'

* 14sep22 RL in M1 model
** stdp.mod implementation
- adapted from george's cleanmodel by cliff
- includes STDP and RL as 2 diff mechanisms -- not dopamine-based STDP! - need to modify
- To implement RL in model need to run reward_punish from each element of stdpmechs (instantiations of stdp.mod = weight
adjuster) eg. every 100 ms: for s in stdpmechs: s.reward_punish
** RL interval?
- error used RL rewards should include difference etween current and previous time step (eg. 5ms) or previous RL update (50
  or 100 ms) ??
- in arm2dms it was errro with previous time step (10 ms) -- but I think it should be prev RL update or maybe Eligibility
  trace interval or motor command window !?
- No EM lag because aready included in the musculoskeletal arm
* 15jan11 Learning targets (reward signal)  :paper:
** reward-modulated STDP between biological neurons and model neurons
- different reward signal to different L2 subpopulations depending on target
- similar to Koca15
- PMd population = 128 neurons = biological neurons
- P population = proprioceptive = PPC / Thalamus (from virtual arm)
- To speed up training: 1) play back vector of PMd inputs; 2) use simple kinematic arm (once working replace with
  musculoskeletal and retrain)
- Start with just 2 targets (left, right); if working move to 4 targets
*** Training: different options from more realistic to more practical
- Feed PMd data (for different targets) and for each one enforce exploratory movements over all targets
- STDP + RL when hand getting closer to correct target
- Plasticity only between PMd->L2; L5/CSP -> Spinal Cord; P->L2 ??
- What connections will be reinforced: those linking PMd data corresponding to target X, with the arm movements to target X
- Need to divide training and testing dataset?
- In L2/3, the accuracy of neuronal ensemble prediction of lever trajectory remained unchanged globally, with a subset of
  individual neurons retaining high prediction accuracy throughout the training period. However, in L5a, the ensemble
  prediction accuracy steadily improved, and one-third of neurons, including subcortical projection neurons, evolved to
  contribute substantially to ensemble prediction in the late stage of learning. The L2/3 network may represent coordination
  of signals from other areas throughout learning, whereas L5a may participate in the evolving network representing
  well-learned movements.(Masamizu et al, 2014)

*** Connectivity: different options from more realistic/autonomous, to more hard-wired/easy to learn
**** PMd -> L2 (all-to-all) overlapping with P -> L2 (all-to-all)
**** PMd -> L2 (all-to-50%), P -> L2 (all-to-other 50%)

* 15jan28 Focus on this model now (2 months to final demo) first steps: mpi, circuitry, conceptual framework
** Debug msarm.py so can run model
- modified msarm to use self. for most variables in run method
- 'randomOutput' arm runs fast, but dummyArm quite slow because has to search/collect spikes to generate motor command
** Test mpi in mac
*** Salvador-Duras-MacBook-Pro% mpiexec -n 4 nrniv -python -mpi model.py
ssh: Could not resolve hostname Salvador-Duras-MacBook-Pro: nodename nor servname provided, or not known
^C[mpiexec@Salvador-Duras-MacBook-Pro] Sending Ctrl-C to processes as requested [mpiexec@Salvador-Duras-MacBook-Pro] Press
Ctrl-C again to force abort [mpiexec@Salvador-Duras-MacBook-Pro] HYDU_sock_write (./utils/sock/sock.c:291): write error (Bad
file descriptor) [mpiexec@Salvador-Duras-MacBook-Pro] HYD_pmcd_pmiserv_send_signal (./pm/pmiserv/pmiserv_cb.c:170): unable to
write data to proxy [mpiexec@Salvador-Duras-MacBook-Pro] ui_cmd_cb (./pm/pmiserv/pmiserv_pmci.c:79): unable to send signal
downstream [mpiexec@Salvador-Duras-MacBook-Pro] HYDT_dmxu_poll_wait_for_event (./tools/demux/demux_poll.c:77): callback
returned error status [mpiexec@Salvador-Duras-MacBook-Pro] HYD_pmci_wait_for_completion (./pm/pmiserv/pmiserv_pmci.c:197):
error waiting for event [mpiexec@Salvador-Duras-MacBook-Pro] main (./ui/mpich/mpiexec.c:331): process manager error waiting
for completion
*** Salvador-Duras-MacBook-Pro% mpiexec
[mpiexec@Salvador-Duras-MacBook-Pro] set_default_values (./ui/mpich/utils.c:1542): no executable provided
[mpiexec@Salvador-Duras-MacBook-Pro] HYD_uii_mpx_get_parameters (./ui/mpich/utils.c:1751): setting default values failed
[mpiexec@Salvador-Duras-MacBook-Pro] main (./ui/mpich/mpiexec.c:153): error parsing parameters Salvador-Duras-MacBook-Pro%
which mpiexec /usr/local/bin/mpich3/bin/mpiexec

*** Salvador-Duras-MacBook-Pro% brew install mpich - works
==> Installing dependencies for mpich2: cloog, gfortran Error: You must `brew link isl' before cloog can be installed
Salvador-Duras-MacBook-Pro% brew link isl Linking /usr/local/Cellar/isl/0.12.1... 9 symlinks created
Salvador-Duras-MacBook-Pro% brew install mpich ==> Installing dependencies for mpich2: cloog, gfortran ==> Installing mpich2
dependency: cloog ==> Downloading https://downloads.sf.net/project/machomebrew/Bottles/cloog-0.18.1.mavericks.bottle.1.tar.gz
######################################################################## 100.0% ==> Pouring
cloog-0.18.1.mavericks.bottle.1.tar.gz 🍺 /usr/local/Cellar/cloog/0.18.1: 33 files, 556K ==> Installing mpich2 dependency:
gfortran ==> Downloading https://downloads.sf.net/project/machomebrew/Bottles/gfortran-4.8.2.mavericks.bottle.1.tar.gz
######################################################################## 100.0% ==> Pouring
gfortran-4.8.2.mavericks.bottle.1.tar.gz ==> Caveats Formulae that require a Fortran compiler should use: depends_on :fortran
==> Summary 🍺 /usr/local/Cellar/gfortran/4.8.2: 960 files, 113M ==> Installing mpich2 ==> Using Homebrew-provided fortran
compiler.  This may be changed by setting the FC environment variable.  ==> Downloading
http://www.mpich.org/static/downloads/3.1/mpich-3.1.tar.gz
######################################################################## 100.0% ==> ./configure --disable-silent-rules
--prefix=/usr/local/Cellar/mpich2/3.1 --mandir=/usr/local/Cellar/mpich2/3.1/share/man ==> make ==> make install 🍺
/usr/local/Cellar/mpich2/3.1: 457 files, 15M, built in 3.3 minutes Salvador-Duras-MacBook-Pro%
*** Warning: detected user attempt to enable MPI, but MPI support was disabled at build time.

** Install NEURON in mac
http://www.neuron.yale.edu/neuron/download/compilestd_osx

brew install mpich build.sh config: ./configure --with-iv=$IVB --prefix=$ND --with-nrnpython=dynamic CC='gcc-4.6'
CCX='g++-4.6' --with-paranrn https://discussions.apple.com/thread/3406578 make make install python setup.py install
--home=/usr/arch/nrn/share/python

*** clean steps from scratch
- install required libraries via brew (list of libs?)
- brew install open-mpi
- cd $NSRC; ./build.sh
-./configure --with-iv=$IVB/iv --prefix=$ND --with-nrnpython=dynamic CC='gcc-4.6' CCX='g++-4.6' --with-paranrn=dynamic
- sudo bash
- export ARCHFLAGS='-arch i386 -arch x86_64'
- cd $ND
- make
- make install
- cd $NB/src/nrnpython
- python setup.py install --home=/usr/arch/nrn/share/python

**** didnt work (see error here)
Salvador-Duras-MacBook-Pro% m1ms Salvador-Duras-MacBook-Pro% /usr/local/Cellar/open-mpi/1.7.4/bin/mpirun -n 4 nrniv -python
-mpi model.py dyld: Library not loaded: /usr/local/lib/libpmpich.12.dylib Referenced from:
/usr/arch/nrn/x86_64/lib/libnrnoc.0.dylib Reason: image not found dyld: Library not loaded: /usr/local/lib/libpmpich.12.dylib
Referenced from: /usr/arch/nrn/x86_64/lib/libnrnoc.0.dylib Reason: image not found dyld: Library not loaded:
/usr/local/lib/libpmpich.12.dylib Referenced from: /usr/arch/nrn/x86_64/lib/libnrnoc.0.dylib Reason: image not found dyld:
Library not loaded: /usr/local/lib/libpmpich.12.dylib Referenced from: /usr/arch/nrn/x86_64/lib/libnrnoc.0.dylib Reason:
image not found -------------------------------------------------------------------------- mpirun noticed that process rank 2
with PID 24333 on node Salvador-Duras-MacBook-Pro exited on signal 5 (Trace/BPT trap: 5).
-------------------------------------------------------------------------- Salvador-Duras-MacBook-Pro% nrniv dyld: Library
not loaded: /usr/local/lib/libpmpich.12.dylib Referenced from: /usr/arch/nrn/x86_64/lib/libnrnoc.0.dylib Reason: image not
found Trace/BPT trap

**** try specifying open-mpi folder - worked!
 ./configure --with-iv=$IVB/iv --prefix=$ND --with-nrnpython=dynamic CC='gcc-4.6' CCX='g++-4.6'
 --with-paranrn=/usr/local/Cellar/open-mpi/1.7.4/

** Define inputs to M1 circuitry :paper:
*** what layer do proprioceptive inputs (via spinal cord+thalamus) target?
- thalamic inputs to upper layers (Weiler et al,2008; Kiritani et al, 2010)
- Thalamocortical inputs from anterior, motor-related thalamic regions (VA/VL) with cerebellar afferents -> L2/3, L5A, L5B (IT+PT)
  (Hooks et al, 2013)
- Posterior sensory-related thalamic areas (POm) -> L2/3 and L5A (Hooks et al, 2013)
- Inputs from sensory-related cortical and thalamic areas preferentially target the upper-layer pyramidal neurons in
  vM1.(Hooks et al, 2013)
- VL axons in the cortex excited both IT and PT neurons (Yamawaki & Shepherd, 2015)
- Area 2 receives its main input from area 1 as well as from the VPS, which is the main relay nucleus for proprioceptive
  information in the monkey. (Francis 2009); Until recently, the rat homolog of the VPS had not been identified, which is
  surprising given the wide spread use of the rat as an animal model. (Francis 2009) --> In macaque proprioceptive info via
  VPS
- Mapped out a region in the rostral VPL of the rat that responds preferentially to joint manipulation and muscle palpation
  (Francis et al. 2008) --> In rat proprioceptive info via VPL

*** what layer do PMd inputs target?
- cortical inputs to upper layers (Weiler et al,2008; Kiritani et al, 2010)
- Orbital cortex (OC) -> L6
- Secondary motor cortex (M2) -> L5B
- Inputs from OC and M2, areas associated with volitional and cognitive aspects of movements, bypass local circuitry and have
  direct monosynaptic access to neurons projecting to brainstem and thalamus.
- In macaque input from PMd seems to go primarily to upper layers (layer 1?) and spread across the rest (based on fig 2 Shipp, 2005) 
- In macaque PMd->M1 target ~55% deep layers and ~45% superficial layers (1-3) (Dum & Strick, 2005)
- In rhesus monkey more than 90% of all labeled neurons within the premotor and motor cortices were found in layer 3; the rest in
  layers 5 and 6 (Barbas & Panday, 1987)

- "In L2/3, the accuracy of neuronal ensemble prediction of lever trajectory remained unchanged globally, with a subset of
  individual neurons retaining high prediction accuracy throughout the training period. However, in L5a, the ensemble
  prediction accuracy steadily improved, and one-third of neurons, including subcortical projection neurons, evolved to
  contribute substantially to ensemble prediction in the late stage of learning. The L2/3 network may represent coordination
  of signals from other areas throughout learning, whereas L5a may participate in the evolving network representing
  well-learned movements" (Masamizu et al, 2014)

** Cell and neuron densities in the primary motor cortex of primates (Young,2013)
** Added new spinal cord populations
*** code
-popnames = ['PMd', 'ASC', 'DSC', 'ER2', 'IF2', 'IL2', 'ER5', 'EB5', 'IF5', 'IL5', 'ER6', 'IF6', 'IL6'] popclasses = [-1, -1,
--1, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3] # Izhikevich population type popEorI = [ 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1] # Whether
-it's excitatory or inhibitory popratios = [numPMd, 48, 48, 150, 25, 25, 167, 72, 40, 40, 192, 32, 32] # Cell population
-numbers
*** description
- PMd = input from PMd with target/reward information; NSLOCs; reproduces PMd recorded data
- ASC = Ascending Spinal Cord; proprioceptive info; encode x-y speed (previously P population encoding muscle lengths); 
- DSC = Descending Spinal Cord; muscle excitations; receives input from EB5 (all-to-all mapping)
  
** Proprioceptive population encodes cartesian direction and velocity :papers:
*** From Roll04
It is widely recognized nowadays that sensory information produced by muscle spindles constitutes a crucial part of
proprioception (Cordo 1990; Gandevia 1996; Gandevia and Burke 1992; Roll 2003). As far as the sensory level is concerned, one
might mention recent studies examining the coding of two-dimensional pointing and drawing movements, the results of which
have shown that muscle spindle population activity is strongly correlated with both the direction and the velocity of the
ongoing movement under both passive and active conditions (Bergenheim et al. 2000; Roll et al. 2000; Jones et al. 2001). In
addition, these studies showed that each muscle spindle is sensitive to a specific range of movement directions (the
so-called preferred sensory sector, PSS), and shows maximum sensitivity to a specific direction (denoted the preferred
sensory direction, PSD). The PSS and the PSD of the various muscle spindles within a given muscle are quite similar, which
makes it possible to calculate an average PSD and PSS for that muscle. Each muscle has its own PSD and PSS which differs from
those of other muscles.  When examining the PSS of the muscle groups acting on the ankle joint, it was observed that they
overlapped in such a way that, together, they covered the whole range of possible movement directions in that particular
joint (Bergenheim et al. 2000; Roll et al. 2000). The authors of the latter studies concluded that the proprioceptive
information arising from all muscles surrounding a joint was needed for accurate sensory and perceptual coding to be
performed throughout the whole movement.  In other studies, using a similar population vector model to that used by Schwartz
(1992, 1993) at the cortical level, it was established that the “sum vector” of all the oriented and weighted activity from
the whole population of muscle spindles in all the muscles acting on a given joint, accurately describes the instantaneous
direction and velocity of the ongoing movement in two dimensional space (Bergenheim et al. 2000; Roll et al. 2000; Jones et
al. 2001; Ribot-Ciscar et al. 2002).

*** From Bosc01 cited in Fran09
XV. SUMMARY

A.  Role of Limb Biomechanics in Global Limb Representations

We have presentedhere a possible framework for interpreting proprioceptive signals at the spinal level. It is based on the
premise that global limb information rather than localized receptor-like proprioceptive information is encoded by the nervous
system. Within a basic global framework, information is encoded by a distributed system in which each neural element may
still bias the global information according to some local detail. For example, the DSCT data suggest that details about
stiffness at a single joint might be contained in a population signal that encodes a representation of the limb end point
that may then depend on the joint covariance resulting from specific levels of joint stiffness.

This global sensory representation is not organized entirely by the neural circuitry however. It begins in the periphery with
the biomechanical structure of the limb. Biomechanical constraints ensure that theactivity from individual sensory receptors
will be correlated in certain ways that depend on whole limb parameters. Therefore, even a minimum of central sensory
convergence could lead to global representations with this peripheral apparatus (37,38, 281).

B.  Significance of Kinematic-Based Representations

We also suggest that this framework could be based on limb kinematics. If so, it is noteworthy that while many participating
sensory receptors are associated with muscles and some even specifically tuned to muscle force, nevertheless their ensemble
is capable of encoding limb kinematics. In other words, inputs from receptors located in individual muscles or associated
deep structures as well as in the skin are assembled at very early stages of central processing to provide a representation
of limb kinematics. Because this occurs at these earliest stages, it suggests that the peripheral apparatus may also in some
way play a role in itsdetermination. The result, however, is that centrally directed sensory information may be encoded in a
framework common to that of central motor activity that relates to limb kinematics. It may therefore be analogous to the
situation in the superior colliculus where sensory information from various modalities is mapped congruently within a
retinotopic map (227, 306) that may be modified or transformed by gaze (123, 124,157, 158); that is, the sensory information
is combined and integrated through a common coding framework. Although the retinal projection may provide the basis for a
common framework for eye, head, and body movement control, limb biomechanics and associated proprioceptors appear to provide
the basis for a common framework for limb movement control.
*** From Berg00
The results show that each muscle spindle afferent, and likewise each muscle, has a specific preferred sensory direction, as
well as a preferred sensory sector within which it is capable of sending sensory information to the central nervous
system. Interestingly, the results also demonstrate that the preferred directions are the same as the directions of
vibration-induced illusions. In addition, the results show that the neuronal population vector model describes the
multipopulation proprioceptive coding of spatially oriented 2D limb movements, even at the peripheral sensory level, based on
the sum vectors calculated from all the muscles involved in the movement.
 

** PMd input with multiple targets requires new conceptual framework! :papers:
- PMd provides preparation activity -- where to go; target info with respect to hand
- Learning adpats weight to map different PMd activity to M1 activity that directs arm to different targets
- ASC population encodes proprioceptive info from arm (direction and velocity) and visual feedback from eyes (arm position;
  or arm - target position) -- doesn't make sense because ASC (=spinal cord) doesn't contain vision; would have to call it
PPC -- if only encode direction (population code for angle) and velocity (amplitude as firing rate), system shouldn't be able
to tell difference if placed in different starting point; however this may not be required because input from PMd is guiding
movement (ie. telling system, go to the right/left etc., not specifying target location!), so can argue hand/target position
more relevant for PMd (?!)  -- when pmd activity dies off (reached target), so should M1 activity?


- "We demonstrate that an MI ensemble can reconstruct hand or joint trajectory more accurately than an equally sized PMd
  ensemble.In contrast, PMd can more precisely predict the future occurrence of one of several discrete targets to be
  reached.These results also support the hierarchical view that MI ensembles are involved in lower-level movement execution,
  whereas PMd populations represent the early intention to move to visually presented targets." Hatsopoulos, 2004

- Above also possible argument for developing model of M1 -- PMd activity itself doesn't provide accurate position/vel representation

* 15feb06 dummyArm
- dummyArm was independent python executable which used udp messages to communicate with model
- udp obsolete (now pipes)
- replaced dummyArm with same code but running within model (no udp or pipes)
- requires all same RL apparatus; after that working test muscskel
* 15feb09 MPI issues: gidDic, motor commands, and RL
** gidVec vs gidDic
- CHECK gidVec vs gidDic
- gidVec is vector local to each node, where index=local id, and value = gid
- gidDic is dictionary local to each node, where key=global id, value = local id 
- redundant! but using gidVec.index() to get the local id is very slow (~300x slower) -- so use gidDic to get local id
*** speed comparison from gil
gidvec.index() takes so long time.  Test for vec.index and dictionary import time import random vec = [] for c in
range(10000): vec.append(c) dic = { x:x for x in range(10000)} seq = range(10000) random.shuffle(seq) measure = time.time()
for c in seq: a = vec.index(c) measure = time.time() - measure print 'vec.index:', measure measure = time.time() for c in
seq: b = dic[c] measure = time.time() - measure print 'dic:', measure

vec.index: 1.80838108063 dic: 0.00332403182983

*** speed comparison in m1 model
10k cells, 1sec sim, 16 cores, with gidVec.index() = 153 sec 10k cells, 1sec sim, 16 cores, with gidDic = 25.9 sec = x5.9
speedup
** differences when using mpi with different number of nodes due to motor commands implementation
- not present when arm is off
- not present when proprio is off -> due to proprio -- not true, also present with propio off 
- joint angles different in 1 vs 16 cores
- not due to broadcasting error - same before and after
- difference in motor commands! - maybe due to timing?
- FOUND: error originates in these 2 lines used to speed up sim by removing past spikes from list:

#self.hostspiketimes = self.hostspiketimes[self.hostspiketimes > (h.t - 2*max(self.shtimewin,self.eltimewin))] # remove
#unncessary old spikes self.hostspikecells = self.hostspikecells[self.hostspiketimes > (h.t - 
2*max(self.shtimewin,self.eltimewin))] # remove unncessary old spikes

JUST HAD TO SWITCH AROUND TO AVOID SPIKETIMES GETTING DELETED BEFORE USING IT TO SEARCH SPIKECELLS!!

- still diffs when add RL

** differences when using mpi with different number of nodes due to RL
- different num of spikes when using 1 vs >1 cores
- was only changing weights in worker0
- seems error related to STDP  -- also happens when RL off
- doesn't happen when STDP off
- also happens in cliff tutorial code
- can reproduce easily with this code: http://neuron.yale.edu/neuron/static/courses/cns2014/large-scale.zip , scale=4,
 duration=3, 1 vs 8 mpi cores 
- also tested in neurosim (zn) /u/salvadord/Documents/ISB/Models/large-scale/
- also happens when using scale=3, dur=3, 4 vs 12 cores (Spikes: 14031 vs 14003)
- compared output: difference in weightchanges (38/83311), spikes (28/14031) and lfp; rest the same:
        distances: [164138x1 double]
             EorI: [3000x1 int64]
          lfptime: [600x1 double]
            ylocs: [3000x1 double]
         cellpops: [3000x1 int64]
         stimdata: []
           delays: [164138x1 double]
      cellclasses: [3000x1 int64]
        cellnames: [3000x3 char]
      connweights: [15x15x4 double]
        connprobs: [15x15 double]
      connections: [164138x2 double]
            xlocs: [3000x1 double]
          weights: [164138x4 double]
          simcode: {7x1 cell}
    weightchanges: {83311x1 cell}
         stdpdata: [83311x3 double]
        spikedata: [14031x2 double]
            zlocs: [3000x1 double]
             lfps: [600x6 double]
*** chat with cliff
cliff I find differences in the number of spikes when using 1 core vs >1 core did u have this problem?  I tested the sim you
used for tutorial and also reproduced it there eg. 1 core = 19771 spikes; 8 cores = 19758 spikes Cliff Kerr hmm that's
strange -- i used to have that problem but it got fixed at some point, could've gotten broken again though...  it had to do
with the random seeds being initialized differently Salvador Dura so how did u fix? maybe I ahve old version hmm ok, I'll
check that I was thinking it was stdp related cause doesn't seem to happen when stdp off -- but need to check more thoroughly
was thinking maybe related to stdp happening between cells in different cores, but just speculation Cliff Kerr each cell
should have its own random number generator linked to gid but it's possible i haven't checked for stdp Salvador Dura so the
random generator error u had, was related to using different number of cores?  Cliff Kerr yeah Salvador Dura cause if I use
the same number of cores, the result is always the same ok it seems when stdp off, error doesnt happen Cliff Kerr
interesting...  Salvador Dura I'll check the rand gen and the stdp code, see if I can find anything Cliff Kerr anyway my
feeling is that it's probably not a big deal, i.e. each one is equally valid, but yeah agree they should match Salvador Dura
@equally valid - yeah probably, but just need for reproducibility of results -- small error could carry forward in time I
guess
sal:can reproduce easily with this code: http://neuron.yale.edu/neuron/static/courses/cns2014/large-scale.zip , scale=4, duration=3, 1 vs 8 mpi cores
cliff: i guess you could check that the stdp connections and weights are the same in the 1 and 8 core cases?

* TODO port msarm to M1 model
** DONE add the input Proprioceptive population, which is actually really a set of netstims with location (NSLOCs), and connect them to layer 2 
** DONE reorganize definition of population/cell parameters
*** DONE set z location based on new yfrac property (0 to 1) for each population
*** DONE population and receptor names within cellpopdata module imported as p (ER2 -> p.ER2)
** TODO Add RL: weight changes at synapses, eligibility traces, stdp-like rule, keep track of target location and arm position (receive via udp every 10ms) to calculate error periodically,
**** DONE Make plexon input be optional 
**** DONE replace arminterface with arminterface_pipe.py - set an option so can use dummy virtual arm for testing!
**** TODO implement msarm.hoc (arm apparatus such as target location, arm position, error etc) in new python-based M1 model
**** DONE fix mpi bug - different motor commands for different nhosts (check if spikes diff as well!!!)
**** DONE RL and eligibility traces using George's PYNDL code
** TODO Assign SPI (spinal cord) subpopulations to different muscles (or maybe just random, which would make more realistic), convert from firing rates to muscle excitation (currently, just sum+threshold), and send udp packet with muscle excitations to arm every 10ms.
**  TODO Assign muscle lengths to the proprioceptive neurons and make them fire accordingly; requires updating muscle lengths every 10ms (via received udp messages)
** TODO Add the training, testing, and analysis functions
** TODO decide where plasticity will happen
-should modify the connectivity and weights tuned to M1!?  -maybe avoid by adding plastic connections ONLY between
proprioception to L2/3? and SPI to spinal cord interneurons; use spinal cord to project to muscles - see 15jan11
** TODO Encode target/PMd activity in input to L2/3 or in external noise input patterns 
- PMd poisson from neural field model/SSM?)  - use SSM from Marius, and convert to Poisson(?) a la cliff - Train with SSM
  noise for each of the targets - Test with initial/preparatory PMd input??
  
